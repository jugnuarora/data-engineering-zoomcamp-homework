{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got month 01 with 2964624 records\n",
      "Got month 02 with 3007526 records\n",
      "Got month 03 with 3582628 records\n",
      "Got month 04 with 3514289 records\n",
      "Got month 05 with 3723833 records\n",
      "Got month 06 with 3539193 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 18:37:29,687|[WARNING]|24183|8226244672|dlt|type_mapping.py|to_db_datetime_type:56|Column flags for timezone or precision are not yet supported in this destination. One or both of these flags were used in column 'tpep_pickup_datetime'. in table 'ny_taxi_dlt'.\n",
      "2025-02-18 18:37:29,688|[WARNING]|24183|8226244672|dlt|type_mapping.py|to_db_datetime_type:56|Column flags for timezone or precision are not yet supported in this destination. One or both of these flags were used in column 'tpep_dropoff_datetime'. in table 'ny_taxi_dlt'.\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/de-zoomcamp/lib/python3.9/site-packages/google/cloud/bigquery/client.py:595: UserWarning: Cannot create BigQuery Storage client, the dependency google-cloud-bigquery-storage is not installed.\n",
      "  warnings.warn(\n",
      "2025-02-18 18:37:33,248|[WARNING]|24183|8226244672|dlt|type_mapping.py|to_db_datetime_type:56|Column flags for timezone or precision are not yet supported in this destination. One or both of these flags were used in column 'tpep_pickup_datetime'. in table 'ny_taxi_dlt'.\n",
      "2025-02-18 18:37:33,249|[WARNING]|24183|8226244672|dlt|type_mapping.py|to_db_datetime_type:56|Column flags for timezone or precision are not yet supported in this destination. One or both of these flags were used in column 'tpep_dropoff_datetime'. in table 'ny_taxi_dlt'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline ny_taxi_pipeline_dlt load step completed in 1 minute and 24.80 seconds\n",
      "1 load package(s) were loaded to destination bigquery and into dataset ny_taxi_parquet_dlt_8_20250218053652\n",
      "The bigquery destination used de-zoomcamp-warehouse@de-zoomcamp-warehouse.iam.gserviceaccount.com@de-zoomcamp-warehouse location to store data\n",
      "Load package 1739900212.89182 is LOADED and contains no failed jobs\n",
      "Normalized data for the following tables:\n",
      "- _dlt_pipeline_state: 1 row(s)\n",
      "- ny_taxi_dlt: 20332093 row(s)\n",
      "\n",
      "Load package 1739900212.89182 is NORMALIZED and NOT YET LOADED to the destination and contains no failed jobs\n"
     ]
    }
   ],
   "source": [
    "import dlt\n",
    "import requests\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import io\n",
    "import os\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Path to your JSON key file\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"gcs.json\"\n",
    "\n",
    "# Base URL for the Parquet files\n",
    "BASE_URL = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-\"\n",
    "MONTHS = [f\"{i:02d}\" for i in range(1, 7)]  # ['01', '02', ..., '06']\n",
    "\n",
    "# Define a dlt resource for fetching Parquet data\n",
    "@dlt.resource(name=\"ny_taxi_dlt\", write_disposition=\"replace\")\n",
    "def paginated_getter():\n",
    "    \"\"\"Fetches and yields monthly Parquet data as Pandas DataFrames.\"\"\"\n",
    "\n",
    "    for month in MONTHS:\n",
    "        url = f\"{BASE_URL}{month}.parquet\"\n",
    "        \n",
    "        try:\n",
    "            # Fetch the Parquet file in streaming mode\n",
    "            with requests.get(url, stream=True) as response:\n",
    "                response.raise_for_status()  # Raise an error for failed requests\n",
    "\n",
    "                # Read file in chunks and store in a buffer\n",
    "                buffer = io.BytesIO()\n",
    "                for chunk in response.iter_content(chunk_size=1024 * 1024):  # Read in 1MB chunks\n",
    "                    buffer.write(chunk)\n",
    "\n",
    "                buffer.seek(0)  # Reset buffer position\n",
    "\n",
    "                # Read Parquet file using pyarrow and convert to Pandas DataFrame\n",
    "                table = pq.read_table(buffer)\n",
    "\n",
    "                print(f'Got month {month} with {len(table)} records')\n",
    "\n",
    "                if table.num_rows > 0:  # If data exists, yield it\n",
    "                    yield table\n",
    "                else:\n",
    "                    break  # Stop if no more data\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to fetch data for month {month}: {e}\")\n",
    "\n",
    "# Create and configure the dlt pipeline\n",
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=\"ny_taxi_pipeline_dlt\",\n",
    "    destination=\"bigquery\",\n",
    "    dataset_name=\"ny_taxi_parquet_dlt_8\",\n",
    "    dev_mode=True\n",
    ")\n",
    "\n",
    "# Run the pipeline and load data into BigQuery\n",
    "load_info = pipeline.run(paginated_getter())\n",
    "\n",
    "# Print load info and normalization details\n",
    "print(load_info)\n",
    "print(pipeline.last_trace.last_normalize_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got month 01 with 2964624 records\n",
      "Got month 02 with 3007526 records\n",
      "Got month 03 with 3582628 records\n",
      "Got month 04 with 3514289 records\n",
      "Got month 05 with 3723833 records\n",
      "Got month 06 with 3539193 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 15:19:23,520|[WARNING]|2896|8226244672|dlt|type_mapping.py|to_db_datetime_type:56|Column flags for timezone or precision are not yet supported in this destination. One or both of these flags were used in column 'tpep_pickup_datetime'. in table 'ny_taxi_dlt'.\n",
      "2025-02-18 15:19:23,520|[WARNING]|2896|8226244672|dlt|type_mapping.py|to_db_datetime_type:56|Column flags for timezone or precision are not yet supported in this destination. One or both of these flags were used in column 'tpep_dropoff_datetime'. in table 'ny_taxi_dlt'.\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/de-zoomcamp/lib/python3.9/site-packages/google/cloud/bigquery/client.py:595: UserWarning: Cannot create BigQuery Storage client, the dependency google-cloud-bigquery-storage is not installed.\n",
      "  warnings.warn(\n",
      "2025-02-18 15:19:24,914|[WARNING]|2896|8226244672|dlt|type_mapping.py|to_db_datetime_type:56|Column flags for timezone or precision are not yet supported in this destination. One or both of these flags were used in column 'tpep_pickup_datetime'. in table 'ny_taxi_dlt'.\n",
      "2025-02-18 15:19:24,915|[WARNING]|2896|8226244672|dlt|type_mapping.py|to_db_datetime_type:56|Column flags for timezone or precision are not yet supported in this destination. One or both of these flags were used in column 'tpep_dropoff_datetime'. in table 'ny_taxi_dlt'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline ny_taxi_pipeline_dlt load step completed in 1 minute and 13.53 seconds\n",
      "1 load package(s) were loaded to destination bigquery and into dataset ny_taxi_parquet_dlt_4\n",
      "The bigquery destination used de-zoomcamp-warehouse@de-zoomcamp-warehouse.iam.gserviceaccount.com@de-zoomcamp-warehouse location to store data\n",
      "Load package 1739888325.855125 is LOADED and contains no failed jobs\n",
      "Normalized data for the following tables:\n",
      "- _dlt_pipeline_state: 1 row(s)\n",
      "- ny_taxi_dlt: 20332093 row(s)\n",
      "\n",
      "Load package 1739888325.855125 is NORMALIZED and NOT YET LOADED to the destination and contains no failed jobs\n"
     ]
    }
   ],
   "source": [
    "import dlt\n",
    "import requests\n",
    "import pandas as pd\n",
    "import io\n",
    "import os\n",
    "from google.cloud import bigquery\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"gcs.json\"\n",
    "\n",
    "# Base URL for the Parquet files\n",
    "BASE_URL = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-\"\n",
    "MONTHS = [f\"{i:02d}\" for i in range(1, 7)]\n",
    "\n",
    "# Define a dlt resource for fetching Parquet data\n",
    "@dlt.resource(name=\"ny_taxi_dlt\", write_disposition=\"replace\")\n",
    "def paginated_getter():\n",
    "    \"\"\"Fetches and yields monthly Parquet data as Pandas DataFrames.\"\"\"\n",
    "\n",
    "    for month in MONTHS:\n",
    "        url = f\"{BASE_URL}{month}.parquet\"\n",
    "        \n",
    "        try:\n",
    "            # Fetch the Parquet file\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()  \n",
    "\n",
    "            # Convert response content into a Pandas DataFrame\n",
    "            page_parquet = pd.read_parquet(io.BytesIO(response.content))\n",
    "\n",
    "            print(f'Got month {month} with {len(page_parquet)} records')\n",
    "\n",
    "            if not page_parquet.empty:  \n",
    "                yield page_parquet\n",
    "            else:\n",
    "                break  \n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to fetch data for month {month}: {e}\")\n",
    "\n",
    "# Create and configure the dlt pipeline\n",
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=\"ny_taxi_pipeline_dlt\",\n",
    "    destination=\"bigquery\",\n",
    "    dataset_name=\"ny_taxi_parquet_dlt_4\"\n",
    ")\n",
    "\n",
    "\n",
    "# Run the pipeline and load data into BigQuery\n",
    "load_info = pipeline.run(paginated_getter())\n",
    "\n",
    "# Print load info and normalization details\n",
    "print(load_info)\n",
    "print(pipeline.last_trace.last_normalize_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with dlt_load_id and dlt_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got month 01 with 2964624 records\n",
      "Got month 02 with 3007526 records\n",
      "Got month 03 with 3582628 records\n",
      "Got month 04 with 3514289 records\n",
      "Got month 05 with 3723833 records\n",
      "Got month 06 with 3539193 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 12:03:19,439|[WARNING]|2896|8226244672|dlt|type_mapping.py|to_db_datetime_type:56|Column flags for timezone or precision are not yet supported in this destination. One or both of these flags were used in column 'tpep_pickup_datetime'. in table 'ny_taxi_dlt'.\n",
      "2025-02-18 12:03:19,439|[WARNING]|2896|8226244672|dlt|type_mapping.py|to_db_datetime_type:56|Column flags for timezone or precision are not yet supported in this destination. One or both of these flags were used in column 'tpep_dropoff_datetime'. in table 'ny_taxi_dlt'.\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/de-zoomcamp/lib/python3.9/site-packages/google/cloud/bigquery/client.py:595: UserWarning: Cannot create BigQuery Storage client, the dependency google-cloud-bigquery-storage is not installed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline ny_taxi_pipeline_dlt load step completed in 2 minutes and 34.67 seconds\n",
      "1 load package(s) were loaded to destination bigquery and into dataset ny_taxi_parquet_dlt\n",
      "The bigquery destination used de-zoomcamp-warehouse@de-zoomcamp-warehouse.iam.gserviceaccount.com@de-zoomcamp-warehouse location to store data\n",
      "Load package 1739875054.172373 is LOADED and contains no failed jobs\n",
      "Normalized data for the following tables:\n",
      "- _dlt_pipeline_state: 1 row(s)\n",
      "- ny_taxi_dlt: 20332093 row(s)\n",
      "\n",
      "Load package 1739875054.172373 is NORMALIZED and NOT YET LOADED to the destination and contains no failed jobs\n"
     ]
    }
   ],
   "source": [
    "import dlt\n",
    "import requests\n",
    "import pandas as pd\n",
    "import io\n",
    "import os\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Path to your JSON key file\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"gcs.json\"\n",
    "\n",
    "# Base URL for the Parquet files\n",
    "BASE_URL = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-\"\n",
    "MONTHS = [f\"{i:02d}\" for i in range(1, 7)]  # ['01', '02', ..., '06']\n",
    "\n",
    "# Define a dlt resource for fetching Parquet data\n",
    "@dlt.resource(name=\"ny_taxi_dlt\", write_disposition=\"replace\")\n",
    "def paginated_getter():\n",
    "    \"\"\"Fetches and yields monthly Parquet data as Pandas DataFrames.\"\"\"\n",
    "    for month in MONTHS:\n",
    "        url = f\"{BASE_URL}{month}.parquet\"\n",
    "        \n",
    "        try:\n",
    "            # Fetch the Parquet file\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()  # Raise an error for failed requests\n",
    "\n",
    "            # Convert response content into a Pandas DataFrame\n",
    "            page_parquet = pd.read_parquet(io.BytesIO(response.content))\n",
    "\n",
    "            print(f'Got month {month} with {len(page_parquet)} records')\n",
    "\n",
    "            if not page_parquet.empty:  # If data exists, yield it\n",
    "                yield page_parquet.to_dict(orient=\"records\")  # Convert to list of dictionaries for dlt\n",
    "            else:\n",
    "                break  # Stop if no more data\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to fetch data for month {month}: {e}\")\n",
    "\n",
    "# Create and configure the dlt pipeline\n",
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=\"ny_taxi_pipeline_dlt\",\n",
    "    destination=\"bigquery\",\n",
    "    dataset_name=\"ny_taxi_parquet_dlt\"\n",
    ")\n",
    "\n",
    "# Run the pipeline and load data into BigQuery\n",
    "load_info = pipeline.run(paginated_getter())\n",
    "\n",
    "# Print load info and normalization details\n",
    "print(load_info)\n",
    "print(pipeline.last_trace.last_normalize_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach:\n",
    "First, I tested yielding the data by printing it directly, following this method: [Extracting Data with dlt](https://dev.to/cmcrawford2/extracting-data-with-dlt-9hl).\n",
    "Then, I replaced the print statements with a dlt pipeline to load the data into BigQuery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import dlt\n",
    "from dlt.sources.filesystem import filesystem, read_parquet\n",
    "import pandas as pd\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got month 01 with 2964624 records\n",
      "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
      "0         2  2024-01-01 00:57:55   2024-01-01 01:17:43              1.0   \n",
      "1         1  2024-01-01 00:03:00   2024-01-01 00:09:36              1.0   \n",
      "2         1  2024-01-01 00:17:06   2024-01-01 00:35:01              1.0   \n",
      "3         1  2024-01-01 00:36:38   2024-01-01 00:44:56              1.0   \n",
      "4         1  2024-01-01 00:46:51   2024-01-01 00:52:57              1.0   \n",
      "\n",
      "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
      "0           1.72         1.0                  N           186            79   \n",
      "1           1.80         1.0                  N           140           236   \n",
      "2           4.70         1.0                  N           236            79   \n",
      "3           1.40         1.0                  N            79           211   \n",
      "4           0.80         1.0                  N           211           148   \n",
      "\n",
      "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
      "0             2         17.7    1.0      0.5        0.00           0.0   \n",
      "1             1         10.0    3.5      0.5        3.75           0.0   \n",
      "2             1         23.3    3.5      0.5        3.00           0.0   \n",
      "3             1         10.0    3.5      0.5        2.00           0.0   \n",
      "4             1          7.9    3.5      0.5        3.20           0.0   \n",
      "\n",
      "   improvement_surcharge  total_amount  congestion_surcharge  Airport_fee  \n",
      "0                    1.0         22.70                   2.5          0.0  \n",
      "1                    1.0         18.75                   2.5          0.0  \n",
      "2                    1.0         31.30                   2.5          0.0  \n",
      "3                    1.0         17.00                   2.5          0.0  \n",
      "4                    1.0         16.10                   2.5          0.0  \n",
      "Got month 02 with 3007526 records\n",
      "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
      "0         2  2024-02-01 00:04:45   2024-02-01 00:19:58              1.0   \n",
      "1         2  2024-02-01 00:56:31   2024-02-01 01:10:53              1.0   \n",
      "2         2  2024-02-01 00:07:50   2024-02-01 00:43:12              2.0   \n",
      "3         1  2024-02-01 00:01:49   2024-02-01 00:10:47              1.0   \n",
      "4         1  2024-02-01 00:37:35   2024-02-01 00:51:15              1.0   \n",
      "\n",
      "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
      "0           4.39         1.0                  N            68           236   \n",
      "1           7.71         1.0                  N            48           243   \n",
      "2          28.69         2.0                  N           132           261   \n",
      "3           1.10         1.0                  N           161           163   \n",
      "4           2.60         1.0                  N           246            79   \n",
      "\n",
      "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
      "0             1         20.5    1.0      0.5        1.28          0.00   \n",
      "1             1         31.0    1.0      0.5        9.00          0.00   \n",
      "2             2         70.0    0.0      0.5        0.00          6.94   \n",
      "3             1          9.3    3.5      0.5        2.85          0.00   \n",
      "4             2         15.6    3.5      0.5        0.00          0.00   \n",
      "\n",
      "   improvement_surcharge  total_amount  congestion_surcharge  Airport_fee  \n",
      "0                    1.0         26.78                   2.5         0.00  \n",
      "1                    1.0         45.00                   2.5         0.00  \n",
      "2                    1.0         82.69                   2.5         1.75  \n",
      "3                    1.0         17.15                   2.5         0.00  \n",
      "4                    1.0         20.60                   2.5         0.00  \n",
      "Got month 03 with 3582628 records\n",
      "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
      "0         1  2024-03-01 00:18:51   2024-03-01 00:23:45              0.0   \n",
      "1         1  2024-03-01 00:26:00   2024-03-01 00:29:06              0.0   \n",
      "2         2  2024-03-01 00:09:22   2024-03-01 00:15:24              1.0   \n",
      "3         2  2024-03-01 00:33:45   2024-03-01 00:39:34              1.0   \n",
      "4         1  2024-03-01 00:05:43   2024-03-01 00:26:22              0.0   \n",
      "\n",
      "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
      "0           1.30         1.0                  N           142           239   \n",
      "1           1.10         1.0                  N           238            24   \n",
      "2           0.86         1.0                  N           263            75   \n",
      "3           0.82         1.0                  N           164           162   \n",
      "4           4.90         1.0                  N           263             7   \n",
      "\n",
      "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
      "0             1          8.6    3.5      0.5        2.70           0.0   \n",
      "1             1          7.2    3.5      0.5        3.00           0.0   \n",
      "2             2          7.9    1.0      0.5        0.00           0.0   \n",
      "3             1          7.9    1.0      0.5        1.29           0.0   \n",
      "4             2         25.4    3.5      0.5        0.00           0.0   \n",
      "\n",
      "   improvement_surcharge  total_amount  congestion_surcharge  Airport_fee  \n",
      "0                    1.0         16.30                   2.5          0.0  \n",
      "1                    1.0         15.20                   2.5          0.0  \n",
      "2                    1.0         10.40                   0.0          0.0  \n",
      "3                    1.0         14.19                   2.5          0.0  \n",
      "4                    1.0         30.40                   2.5          0.0  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to fetch data for month \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m page_data \u001b[38;5;129;01min\u001b[39;00m paginated_getter():\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28mprint\u001b[39m(page_data\u001b[38;5;241m.\u001b[39mhead())\n",
      "Cell \u001b[0;32mIn[6], line 13\u001b[0m, in \u001b[0;36mpaginated_getter\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBASE_URL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmonth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Fetch the Parquet file\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()  \u001b[38;5;66;03m# Raise an error for failed requests\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Convert response content into a Pandas DataFrame\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/de-zoomcamp/lib/python3.9/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/de-zoomcamp/lib/python3.9/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/de-zoomcamp/lib/python3.9/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/de-zoomcamp/lib/python3.9/site-packages/requests/sessions.py:745\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[0;32m--> 745\u001b[0m     \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/de-zoomcamp/lib/python3.9/site-packages/requests/models.py:899\u001b[0m, in \u001b[0;36mResponse.content\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 899\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content_consumed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/de-zoomcamp/lib/python3.9/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/de-zoomcamp/lib/python3.9/site-packages/urllib3/response.py:628\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp):\n\u001b[0;32m--> 628\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m    631\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/de-zoomcamp/lib/python3.9/site-packages/urllib3/response.py:567\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    564\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 567\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    569\u001b[0m         flush_decoder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/de-zoomcamp/lib/python3.9/site-packages/urllib3/response.py:533\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m buffer\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/de-zoomcamp/lib/python3.9/http/client.py:463\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;66;03m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[1;32m    462\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(amt)\n\u001b[0;32m--> 463\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b)[:n]\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;66;03m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;66;03m# and self.chunked\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/de-zoomcamp/lib/python3.9/http/client.py:507\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    502\u001b[0m         b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmemoryview\u001b[39m(b)[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength]\n\u001b[1;32m    504\u001b[0m \u001b[38;5;66;03m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;66;03m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m n \u001b[38;5;129;01mand\u001b[39;00m b:\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/de-zoomcamp/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/de-zoomcamp/lib/python3.9/ssl.py:1242\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1239\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1240\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1241\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1243\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/de-zoomcamp/lib/python3.9/ssl.py:1100\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1100\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1102\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Base URL for the Parquet files\n",
    "BASE_URL = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-\"\n",
    "MONTHS = [f\"{i:02d}\" for i in range(1, 7)]  # Generates ['01', '02', ..., '06']\n",
    "\n",
    "def paginated_getter():\n",
    "    \"\"\"Fetches and yields monthly Parquet data as Pandas DataFrames.\"\"\"\n",
    "\n",
    "    for month in MONTHS:\n",
    "        url = f\"{BASE_URL}{month}.parquet\"\n",
    "        \n",
    "        try:\n",
    "            # Fetch the Parquet file\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()  # Raise an error for failed requests\n",
    "\n",
    "            # Convert response content into a Pandas DataFrame\n",
    "            page_parquet = pd.read_parquet(io.BytesIO(response.content))\n",
    "\n",
    "            print(f'Got month {month} with {len(page_parquet)} records')\n",
    "\n",
    "            if not page_parquet.empty:  # If data exists, yield it\n",
    "                yield page_parquet\n",
    "            else:\n",
    "                break  # Stop if no more data\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to fetch data for month {month}: {e}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for page_data in paginated_getter():\n",
    "        print(page_data.head())  # Process data (example: print first 5 rows)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "de-zoomcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
